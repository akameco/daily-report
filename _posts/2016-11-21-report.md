---
layout: post
title: "DeepDiary"
date: 2016-11-21
categories: report
---

## task

### week

### today
- [x] 2h 論文 (4h)
- [x] 1h Qiitaに投稿した記事の編集 (2h)
- [ ] 2h im2txtを試す

## 2h 論文 5h
[[1608.03819] DeepDiary: Automatic Caption Generation for Lifelogging Image Streams](https://arxiv.org/abs/1608.03819)
### どんなもの？
ライフログ画像を効果的にブラウズためにDNNを利用した。
CNN+RNN(LSTM)を使って学習。
### 先行研究と比べてどこがすごい？
ライフログ系の論文は見る限り見つかない。
なぜなら、キャプションの自動生成の手法は近年出てきた手法であるため。
### 技術や手法のキモはどこ？
時間的整合性制約を利用。
ビームサーチを利用し多様性を考慮した。
### どうやって有効だと検証した？
COCOのデータを用いた。
定量的な評価(7つのテストの平均)と人を使った評価の2種類を行った。
### 議論はある？
データの隔たりはなかったかが疑問。
実際のアプリケーションでは、トレードオフになる部分がある。
### 次に読むべき論文は？
A. Karpathy and L. Fei-Fei. Deep visual-semantic alignments for generating image descriptions. arXiv:1412.2306, 2014.

Fei-Fei Li氏の論文を読んでおけば間違いなさそう。
